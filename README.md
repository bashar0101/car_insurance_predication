## ğŸ“˜ Introduction 

This project is conducted as part of the **Data Mining** course and focuses on applying **classification techniques** to a real-world dataset.  
The dataset consists of **10,000 records** with various features related to:

- ğŸ‘¤ **Individuals' demographics**
- ğŸš— **Driving behavior**
- ğŸš™ **Vehicle information**
- ğŸ’³ **Credit background**

The **primary goal** is to **predict the `OUTCOME` attribute**, which serves as the **target variable** for classification.  
This attribute indicates whether a customer **accepted (1)** or **rejected (0)** an insurance offer.

ğŸ“Š The data was collected by an **insurance company**, with some instances being **randomly generated** to enrich the dataset.

---

## ğŸ¤– Algorithms Used

We trained the model using **12 different classification algorithms**, including both traditional and ensemble methods:

- ğŸŒ³ **Decision Tree**
- ğŸ¤ **K-Nearest Neighbors (KNN)**
- ğŸ’» **Support Vector Machine (SVM)**
- ğŸ§  **Naive Bayes**
- ğŸ§¬ **Neural Network**
- ğŸš€ **Gradient Boosting (gBoost)**
- âš¡ **AdaBoost**
- ğŸ›¡ï¸ **Bagging**
- ğŸ§¨ **Extreme Gradient Boosting (xgBoost)**
- ğŸ“ˆ **Logistic Regression**
- ğŸŒ² **Extra Trees Classifier (xTree)**
- ğŸŒ³ğŸŒ³ **Random Forest Classifier**

---

## ğŸ“ Model Evaluation

We compared the performance of these models using appropriate **evaluation metrics**:

- ğŸ¯ **Accuracy**
- ğŸ¯ **Precision**
- ğŸ¯ **Recall**
- ğŸ¯ **F1-Score**
- ğŸ¯ **AUC**

These metrics help us determine which model best predicts the **OUTCOME** and provides insights into the **factors influencing customer decisions**.

---
