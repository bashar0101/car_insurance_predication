## 📘 Introduction 

This project is conducted as part of the **Data Mining** course and focuses on applying **classification techniques** to a real-world dataset.  
The dataset consists of **10,000 records** with various features related to:

- 👤 **Individuals' demographics**
- 🚗 **Driving behavior**
- 🚙 **Vehicle information**
- 💳 **Credit background**

The **primary goal** is to **predict the `OUTCOME` attribute**, which serves as the **target variable** for classification.  
This attribute indicates whether a customer **accepted (1)** or **rejected (0)** an insurance offer.

📊 The data was collected by an **insurance company**, with some instances being **randomly generated** to enrich the dataset.

---

## 🤖 Algorithms Used

We trained the model using **12 different classification algorithms**, including both traditional and ensemble methods:

- 🌳 **Decision Tree**
- 🤝 **K-Nearest Neighbors (KNN)**
- 💻 **Support Vector Machine (SVM)**
- 🧠 **Naive Bayes**
- 🧬 **Neural Network**
- 🚀 **Gradient Boosting (gBoost)**
- ⚡ **AdaBoost**
- 🛡️ **Bagging**
- 🧨 **Extreme Gradient Boosting (xgBoost)**
- 📈 **Logistic Regression**
- 🌲 **Extra Trees Classifier (xTree)**
- 🌳🌳 **Random Forest Classifier**

---

## 📏 Model Evaluation

We compared the performance of these models using appropriate **evaluation metrics**:

- 🎯 **Accuracy**
- 🎯 **Precision**
- 🎯 **Recall**
- 🎯 **F1-Score**
- 🎯 **AUC**

These metrics help us determine which model best predicts the **OUTCOME** and provides insights into the **factors influencing customer decisions**.

---
